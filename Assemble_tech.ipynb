{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f10418-61c0-4ff2-b605-13731b3a38e4",
   "metadata": {},
   "source": [
    "Q1. What is an ensemble technique in machine learning?\n",
    "An ensemble technique in machine learning involves combining multiple models to create a stronger, more robust model. The idea is that by aggregating the predictions from several models, the overall performance improves compared to individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bc51a-ee7c-42bd-94e2-a5bad7b4bd9d",
   "metadata": {},
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?\n",
    "Ensemble techniques are used in machine learning for the following reasons:\n",
    "\n",
    "Improved Accuracy: Combining predictions from multiple models can correct errors from individual models.\n",
    "Reduced Overfitting: Ensembles can generalize better to new data than individual models, thereby reducing overfitting.\n",
    "Increased Stability: Ensembles tend to be more stable and less sensitive to the specific quirks of the training data.\n",
    "Diverse Models: Using diverse models can capture different aspects of the data and improve overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5099545-53c6-4f17-810c-fbe5c3902865",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q3. What is bagging?\n",
    "\n",
    "Bagging (Bootstrap Aggregating) is an ensemble technique that involves training multiple instances of the same model on different subsets of the training data created using bootstrap sampling. The final prediction is typically made by averaging the predictions (for regression) or taking a majority vote (for classification) from all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d15fb-f03f-4db0-bd07-a5a022e72ae9",
   "metadata": {},
   "source": [
    "Q4. What is boosting?\n",
    "Boosting is an ensemble technique that combines weak learners to create a strong learner. Unlike bagging, where models are trained independently, boosting trains models sequentially. Each new model focuses on correcting the errors made by the previous models. The final model is a weighted sum of the individual models' predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a716d-03ea-401c-9291-379fb7c04771",
   "metadata": {},
   "source": [
    "Q5. What are the benefits of using ensemble techniques?\n",
    "The benefits of using ensemble techniques include:\n",
    "\n",
    "Higher Predictive Accuracy: Ensembles often outperform single models by leveraging the strengths of multiple models.\n",
    "Reduced Variance: By combining multiple models, the variance of the prediction can be reduced.\n",
    "Robustness: Ensembles are more robust to outliers and noise in the data.\n",
    "Flexibility: Different types of models can be combined to take advantage of their respective strengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c018f-7a9a-4bb2-9ee4-62b98bd55d51",
   "metadata": {},
   "source": [
    "Q6. Are ensemble techniques always better than individual models?\n",
    "No, ensemble techniques are not always better than individual models. There are cases where:\n",
    "\n",
    "Overfitting: An ensemble can still overfit, especially if the individual models are highly complex.\n",
    "Increased Complexity: Ensembles can be more complex and harder to interpret.\n",
    "Computational Cost: Training and maintaining multiple models require more computational resources.\n",
    "Diminishing Returns: The improvement from adding more models may become negligible after a certain point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c0afa-0da9-459e-a3c4-f8d2dd8fd9c5",
   "metadata": {},
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?\n",
    "To calculate the confidence interval using bootstrap, follow these steps:\n",
    "\n",
    "Resample with Replacement: Create many bootstrap samples from the original dataset by randomly sampling with replacement.\n",
    "Calculate Statistic: For each bootstrap sample, calculate the statistic of interest (e.g., mean, median).\n",
    "Aggregate Results: Aggregate the calculated statistics from all bootstrap samples to form a distribution.\n",
    "Determine Interval: Determine the confidence interval by selecting the appropriate percentiles from the bootstrap distribution (e.g., the 2.5th and 97.5th percentiles for a 95% confidence interval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818e736-4b3d-4ffc-8cc4-3c53a809e079",
   "metadata": {},
   "source": [
    "Q8. How does bootstrap work and what are the steps involved in bootstrap?\n",
    "Bootstrap works by generating multiple resamples from the original dataset to estimate the sampling distribution of a statistic. The steps involved are:\n",
    "\n",
    "Original Sample: Start with an original dataset of size \n",
    "n.\n",
    "Resample: Generate multiple (e.g., 1000) bootstrap samples by randomly sampling with replacement from the original dataset, each of size \n",
    "n.\n",
    "Calculate Statistic: Compute the statistic of interest for each bootstrap sample.\n",
    "Create Distribution: Form a distribution of the computed statistics.\n",
    "Confidence Interval: Use the bootstrap distribution to estimate confidence intervals or other properties of the statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e814a8-6a05-48be-9c78-59786226c87e",
   "metadata": {},
   "source": [
    "Q9. Estimating the 95% Confidence Interval for Population Mean Height Using Bootstrap\n",
    "Given:\n",
    "\n",
    "Sample mean height (\n",
    "ˉ\n",
    "x\n",
    "ˉ\n",
    " ) = 15 meters\n",
    "Sample standard deviation (s) = 2 meters\n",
    "Sample size (n) = 50\n",
    "To estimate the 95% confidence interval using bootstrap in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5ac044-38b1-4772-b55c-e295c34b6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [14.03, 15.09]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given sample data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sample_data = np.random.normal(15, 2, 50)  # Simulate sample data with mean 15 and std 2\n",
    "\n",
    "# Bootstrap resampling\n",
    "n_iterations = 1000\n",
    "n_size = len(sample_data)\n",
    "bootstrap_means = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample = np.random.choice(sample_data, n_size, replace=True)\n",
    "    # Calculate mean of bootstrap sample\n",
    "    bootstrap_mean = np.mean(bootstrap_sample)\n",
    "    bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(f\"95% Confidence Interval: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be6d20-8b56-43f7-add9-d86140e825ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
